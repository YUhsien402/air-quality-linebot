import streamlit as st
import os
import time
import hmac
import hashlib
import requests
import pandas as pd
import datetime
import urllib3
import plotly.graph_objects as go
from PIL import Image

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è®€å–åœ–ç‰‡
logo = Image.open("åœ–ç‰‡1.png")

st.set_page_config(
    page_title="å—å€æ¡ˆç©ºæ°£å“è³ªæŸ¥è©¢ç³»çµ±",
    page_icon=logo,
    layout="wide"
)

try:
    AIRLINK_API_KEY = st.secrets["API_KEY"]
    AIRLINK_API_SECRET = st.secrets["API_SECRET"]
    AIRLINK_STATION_ID = st.secrets["STATION_ID"]
    MOENV_API_TOKEN = st.secrets["MOENV_API_TOKEN"]
except:
    AIRLINK_API_KEY = os.getenv("API_KEY", "")
    AIRLINK_API_SECRET = os.getenv("API_SECRET", "")
    AIRLINK_STATION_ID = os.getenv("STATION_ID", "")
    MOENV_API_TOKEN = os.getenv("MOENV_API_TOKEN", "")

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
</style>
""", unsafe_allow_html=True)


def generate_signature(api_key, api_secret, t, station_id, start_ts, end_ts):
    parts = ["api-key", api_key, "end-timestamp", str(end_ts), "start-timestamp", str(start_ts), "station-id",
             str(station_id), "t", str(t)]
    data = "".join(parts)
    return hmac.new(api_secret.encode(), data.encode(), hashlib.sha256).hexdigest()


def fetch_airlink_historical(api_key, api_secret, station_id, start_ts, end_ts):
    t = int(time.time())
    signature = generate_signature(api_key, api_secret, t, station_id, start_ts, end_ts)
    url = "https://api.weatherlink.com/v2/historic/" + str(station_id)
    params = {"api-key": api_key, "t": t, "start-timestamp": start_ts, "end-timestamp": end_ts,
              "api-signature": signature}
    try:
        resp = requests.get(url, params=params, timeout=30)
        if resp.status_code != 200:
            return None
        return resp.json()
    except Exception as e:
        st.error("AirLink API éŒ¯èª¤: " + str(e))
        return None


def fetch_airlink_data(api_key, api_secret, station_id, lsids_dict, start_dt, end_dt_fetch, progress_bar):
    all_records = []
    current_dt = start_dt
    total_days = (end_dt_fetch - start_dt).days
    if total_days <= 0:
        total_days = 1
    day_count = 0

    while current_dt < end_dt_fetch:
        next_dt = min(current_dt + datetime.timedelta(days=1), end_dt_fetch)
        start_ts = int(current_dt.timestamp())
        end_ts = int(next_dt.timestamp())
        data = fetch_airlink_historical(api_key, api_secret, station_id, start_ts, end_ts)

        if data:
            sensors = data.get("sensors", [])
            for sensor in sensors:
                lsid = sensor.get("lsid")
                if lsid not in lsids_dict:
                    continue
                device_name = lsids_dict[lsid]
                sensor_data = sensor.get("data", [])
                for record in sensor_data:
                    timestamp = datetime.datetime.fromtimestamp(record["ts"])
                    date_str = timestamp.strftime("%Y/%m/%d")
                    datetime_str = timestamp.strftime("%Y/%m/%d %H:%M")
                    pm25 = record.get("pm_2p5_avg") or record.get("pm_2p5") or record.get("pm_2p5_last")
                    pm10 = record.get("pm_10_avg") or record.get("pm_10") or record.get("pm_10_last")
                    if pm25 is not None or pm10 is not None:
                        all_records.append({
                            "device": device_name,
                            "date": date_str,
                            "datetime": datetime_str,
                            "PM2.5": round(pm25, 1) if pm25 else None,
                            "PM10": round(pm10, 1) if pm10 else None
                        })

        current_dt = next_dt
        day_count += 1
        if progress_bar:
            progress_value = min(day_count / total_days, 1.0)
            progress_bar.progress(progress_value)
        time.sleep(1)
    return all_records


def clean_concentration(value):
    if pd.isna(value):
        return None
    value_str = str(value).strip()
    invalid_markers = ['#', '*', 'x', 'A', 'NR']
    if value_str in invalid_markers or value_str == '':
        return None
    for marker in invalid_markers:
        if marker in value_str:
            return None
    try:
        numeric_value = float(value_str)
        if 0 <= numeric_value <= 1000:
            return numeric_value
    except:
        pass
    return None


def fetch_moenv_station(dataset_id, api_token, start_date, end_date):
    api_url = "https://data.moenv.gov.tw/api/v2"
    all_records = []
    offset = 0
    limit = 1000
    date_filter = "monitordate,GR," + start_date + " 00:00:00|monitordate,LE," + end_date + " 23:59:59|itemid,EQ,33,4"

    while True:
        url = api_url + "/" + dataset_id
        params = {"api_key": api_token, "format": "json", "offset": offset, "limit": limit, "filters": date_filter}
        try:
            response = requests.get(url, params=params, timeout=30, verify=False)
            response.raise_for_status()
            data = response.json()
            records = data.get("records", [])
            if not records:
                break
            all_records.extend(records)
            if len(records) < limit:
                break
            offset += limit
            time.sleep(0.5)
        except Exception as e:
            st.error("ç’°ä¿ç½² API éŒ¯èª¤: " + str(e))
            break
    return all_records


# åˆå§‹åŒ– session state
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'all_daily' not in st.session_state:
    st.session_state.all_daily = None
if 'airlink_records' not in st.session_state:
    st.session_state.airlink_records = None
if 'moenv_records' not in st.session_state:
    st.session_state.moenv_records = None
if 'result_df' not in st.session_state:
    st.session_state.result_df = None
if 'available_stations' not in st.session_state:
    st.session_state.available_stations = None
if 'start_dt' not in st.session_state:
    st.session_state.start_dt = None
if 'end_dt' not in st.session_state:
    st.session_state.end_dt = None
if 'pivot_pm25' not in st.session_state:
    st.session_state.pivot_pm25 = None
if 'pivot_pm10' not in st.session_state:
    st.session_state.pivot_pm10 = None

# é¡¯ç¤º Logo å’Œæ¨™é¡Œ
st.markdown("""
<style>
.logo-title-container {
    text-align: center;
    margin-bottom: 2rem;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.5rem;
}
.logo-title-container img {
    width: clamp(100px, 20vw, 150px);
    height: auto;
    display: block;
    margin: 0 auto;
}
.main-title {
  text-align: center;
  font-size: clamp(1.2rem, 3.5vw, 2rem);
  font-weight: bold;
  color: #0088cc;
  margin-top: -85px;
  margin-left: 50px; 
  line-height: 1.3;
  padding: 0 1rem;
  word-wrap: break-word;
}
}
/* æ‰‹æ©Ÿç‰ˆèª¿æ•´ */
@media (max-width: 768px) {
    .main-title {
        font-size: 1.3rem;
    }

    .logo-title-container img {
        width: 100px;
    }

    .logo-title-container {
        gap: 0.3rem;
    }
}
/* å¹³æ¿ç‰ˆèª¿æ•´ */
@media (min-width: 769px) and (max-width: 1024px) {
    .main-title {
        font-size: 1.6rem;
    }
}
</style>
""", unsafe_allow_html=True)

# ä½¿ç”¨å–®ä¸€å®¹å™¨ä¾†ç¢ºä¿å…ƒç´ ä¸æœƒåˆ†é›¢
st.markdown('<div class="logo-title-container">', unsafe_allow_html=True)
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.image("åœ–ç‰‡1.png", width=100)
st.markdown('''
<div class="main-title">
å—å€æ¡ˆç©ºæ°£å“è³ªæŸ¥è©¢ç³»çµ±
</div>
</div>
''', unsafe_allow_html=True)

with st.sidebar:
    st.header("ğŸ“… æŸ¥è©¢è¨­å®š")
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("èµ·å§‹æ—¥æœŸ", value=datetime.date(2025, 10, 1))
    with col2:
        end_date = st.date_input("çµæŸæ—¥æœŸ", value=datetime.date(2025, 10, 7))
    st.divider()
    st.subheader("ğŸ¯ æ¸¬ç«™è³‡è¨Š")
    st.markdown("- **AirLink**: å—å€ä¸Šã€å—å€ä¸‹\n- **ç’°ä¿ç½²**: ä»æ­¦ã€æ¥ æ¢“")
    st.divider()
    query_button = st.button("ğŸ” é–‹å§‹æŸ¥è©¢", use_container_width=True, type="primary")
    st.divider()
    st.caption("ç³»çµ±ç‹€æ…‹")
    if AIRLINK_API_KEY and AIRLINK_API_SECRET and AIRLINK_STATION_ID:
        st.success("âœ… AirLink å·²è¨­å®š")
    else:
        st.warning("âš ï¸ AirLink æœªè¨­å®š")
    if MOENV_API_TOKEN:
        st.success("âœ… ç’°ä¿ç½² å·²è¨­å®š")
    else:
        st.warning("âš ï¸ ç’°ä¿ç½² æœªè¨­å®š")

if query_button:
    if not all([AIRLINK_API_KEY, AIRLINK_API_SECRET, AIRLINK_STATION_ID, MOENV_API_TOKEN]):
        st.error("âš ï¸ ç³»çµ±æœªæ­£ç¢ºè¨­å®šï¼Œè«‹è¯çµ¡ç®¡ç†å“¡")
        st.stop()

    AIRLINK_LSIDS = {652269: "å—å€ä¸Š", 655484: "å—å€ä¸‹"}
    MOENV_STATIONS = {"AQX_P_237": "ä»æ­¦", "AQX_P_241": "æ¥ æ¢“"}
    STATION_ORDER = ["ä»æ­¦", "æ¥ æ¢“", "å—å€ä¸Š", "å—å€ä¸‹"]

    # è·ŸåŸå§‹ç‰ˆæœ¬ä¸€è‡´çš„æ—¥æœŸè™•ç†
    start_dt = datetime.datetime.combine(start_date, datetime.time.min)
    end_dt = datetime.datetime.combine(end_date, datetime.time.min)
    end_dt_fetch = end_dt + datetime.timedelta(days=1)

    try:
        st.subheader("ğŸŒ AirLink è³‡æ–™")
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("æ­£åœ¨æŠ“å– AirLink è³‡æ–™...")

        airlink_records = fetch_airlink_data(AIRLINK_API_KEY, AIRLINK_API_SECRET, AIRLINK_STATION_ID, AIRLINK_LSIDS,
                                             start_dt, end_dt_fetch, progress_bar)
        status_text.success("âœ… æŠ“å– " + str(len(airlink_records)) + " ç­† AirLink è³‡æ–™")

        st.subheader("ğŸ›ï¸ ç’°ä¿ç½²è³‡æ–™")
        status_text2 = st.empty()
        status_text2.text("æ­£åœ¨æŠ“å–ç’°ä¿ç½²è³‡æ–™...")
        moenv_records = []
        moenv_start = start_dt.strftime("%Y-%m-%d")
        moenv_end = end_dt.strftime("%Y-%m-%d")
        for dataset_id, station_name in MOENV_STATIONS.items():
            records = fetch_moenv_station(dataset_id, MOENV_API_TOKEN, moenv_start, moenv_end)
            for record in records:
                record['station_name'] = station_name
            moenv_records.extend(records)
        status_text2.success("âœ… æŠ“å– " + str(len(moenv_records)) + " ç­†ç’°ä¿ç½²è³‡æ–™")

        st.subheader("ğŸ“‹ è³‡æ–™æ•´ç†")
        airlink_df = pd.DataFrame(airlink_records)
        if not airlink_df.empty:
            airlink_daily = airlink_df.groupby(["device", "date"]).agg({"PM2.5": "mean", "PM10": "mean"}).reset_index()
            airlink_daily["PM2.5"] = airlink_daily["PM2.5"].round(0).astype(int)
            airlink_daily["PM10"] = airlink_daily["PM10"].round(0).astype(int)
        else:
            airlink_daily = pd.DataFrame()

        moenv_df = pd.DataFrame(moenv_records)
        if not moenv_df.empty:
            moenv_df['concentration'] = moenv_df['concentration'].apply(clean_concentration)
            moenv_df = moenv_df[moenv_df['concentration'].notna()].copy()
            moenv_df['concentration'] = pd.to_numeric(moenv_df['concentration'], errors='coerce')
            moenv_df['itemid'] = moenv_df['itemid'].astype(str)
            moenv_df['date'] = pd.to_datetime(moenv_df['monitordate']).dt.date
            moenv_df['date'] = moenv_df['date'].astype(str).str.replace('-', '/')
            moenv_df = moenv_df[moenv_df['itemid'].isin(['33', '4'])].copy()
            moenv_df['pollutant'] = moenv_df['itemid'].map({'33': 'PM2.5', '4': 'PM10'})
            moenv_daily = moenv_df.groupby(['station_name', 'date', 'pollutant']).agg(
                {'concentration': 'mean'}).reset_index()
            moenv_daily_wide = moenv_daily.pivot_table(index=['station_name', 'date'], columns='pollutant',
                                                       values='concentration').reset_index()
            moenv_daily_wide['PM2.5'] = moenv_daily_wide['PM2.5'].round(0).astype(int)
            moenv_daily_wide['PM10'] = moenv_daily_wide['PM10'].round(0).astype(int)
            moenv_daily_wide.rename(columns={'station_name': 'device'}, inplace=True)
        else:
            moenv_daily_wide = pd.DataFrame()

        if not airlink_daily.empty and not moenv_daily_wide.empty:
            all_daily = pd.concat([airlink_daily, moenv_daily_wide], ignore_index=True)
        elif not airlink_daily.empty:
            all_daily = airlink_daily
        elif not moenv_daily_wide.empty:
            all_daily = moenv_daily_wide
        else:
            st.error("âŒ æ²’æœ‰ä»»ä½•è³‡æ–™")
            st.stop()

        # éæ¿¾æ—¥æœŸç¯„åœï¼ˆåªä¿ç•™ start_date åˆ° end_dateï¼‰
        start_date_str = start_dt.strftime("%Y/%m/%d")
        end_date_str = end_dt.strftime("%Y/%m/%d")
        all_daily = all_daily[(all_daily['date'] >= start_date_str) & (all_daily['date'] <= end_date_str)].copy()

        available_stations = [s for s in STATION_ORDER if s in all_daily['device'].unique()]
        pivot_pm25 = all_daily.pivot(index='date', columns='device', values='PM2.5')
        pivot_pm10 = all_daily.pivot(index='date', columns='device', values='PM10')

        pivot_pm25 = pivot_pm25[[s for s in available_stations if s in pivot_pm25.columns]]
        pivot_pm10 = pivot_pm10[[s for s in available_stations if s in pivot_pm10.columns]]

        result_df = pd.DataFrame()

        # è½‰æ›æ—¥æœŸç‚ºæ°‘åœ‹å¹´æ ¼å¼
        dates_roc = []
        for date_str in pivot_pm25.index:
            parts = date_str.split('/')
            year_roc = int(parts[0]) - 1911
            month = int(parts[1])
            day = int(parts[2])
            dates_roc.append(str(year_roc) + "/" + str(month) + "/" + str(day))

        result_df['æ—¥æœŸ'] = dates_roc

        for station in available_stations:
            if station in pivot_pm25.columns:
                result_df[station + '_PM2.5'] = pivot_pm25[station].values
                result_df[station + '_PM10'] = pivot_pm10[station].values

        # å„²å­˜åˆ° session state
        st.session_state.data_loaded = True
        st.session_state.all_daily = all_daily
        st.session_state.airlink_records = airlink_records
        st.session_state.moenv_records = moenv_records
        st.session_state.result_df = result_df
        st.session_state.available_stations = available_stations
        st.session_state.start_dt = start_dt
        st.session_state.end_dt = end_dt
        st.session_state.pivot_pm25 = pivot_pm25
        st.session_state.pivot_pm10 = pivot_pm10

    except Exception as e:
        st.error("âŒ ç™¼ç”ŸéŒ¯èª¤: " + str(e))
        import traceback

        st.code(traceback.format_exc())

if st.session_state.data_loaded:
    all_daily = st.session_state.all_daily
    airlink_records = st.session_state.airlink_records
    moenv_records = st.session_state.moenv_records
    result_df = st.session_state.result_df
    available_stations = st.session_state.available_stations
    start_dt = st.session_state.start_dt
    end_dt = st.session_state.end_dt
    pivot_pm25 = st.session_state.pivot_pm25
    pivot_pm10 = st.session_state.pivot_pm10

    st.subheader("ğŸ“… æ¯æ—¥å¹³å‡å€¼")
    st.dataframe(result_df, use_container_width=True, height=400)

    st.subheader("ğŸ“ˆ è¶¨å‹¢åˆ†æ")
    view_mode = st.radio("é¸æ“‡æ™‚é–“åˆ»åº¦", ["æ¯æ—¥å¹³å‡", "æ¯å°æ™‚å¹³å‡"], horizontal=True)

    if view_mode == "æ¯æ—¥å¹³å‡":
        fig_pm25 = go.Figure()
        for station in available_stations:
            station_data = all_daily[all_daily['device'] == station].sort_values('date')
            fig_pm25.add_trace(
                go.Scatter(x=station_data['date'], y=station_data['PM2.5'], mode='lines+markers', name=station,
                           line=dict(width=3), marker=dict(size=8)))
        fig_pm25.add_hline(y=30, line_dash="dash", line_color="red", annotation_text="æ³•è¦æ¨™æº– 30")
        fig_pm25.update_layout(title="PM2.5 æ¯æ—¥å¹³å‡è¶¨å‹¢", xaxis_title="æ—¥æœŸ", yaxis_title="PM2.5", height=450)
        st.plotly_chart(fig_pm25, use_container_width=True)

        fig_pm10 = go.Figure()
        for station in available_stations:
            station_data = all_daily[all_daily['device'] == station].sort_values('date')
            fig_pm10.add_trace(
                go.Scatter(x=station_data['date'], y=station_data['PM10'], mode='lines+markers', name=station,
                           line=dict(width=3), marker=dict(size=8)))
        fig_pm10.add_hline(y=75, line_dash="dash", line_color="red", annotation_text="æ³•è¦æ¨™æº– 75")
        fig_pm10.update_layout(title="PM10 æ¯æ—¥å¹³å‡è¶¨å‹¢", xaxis_title="æ—¥æœŸ", yaxis_title="PM10", height=450)
        st.plotly_chart(fig_pm10, use_container_width=True)

    else:
        st.info("ğŸ“Š é¡¯ç¤ºæ¯å°æ™‚å¹³å‡å€¼")

        # æº–å‚™æ¯å°æ™‚è³‡æ–™
        hourly_records = []
        for record in airlink_records:
            if 'datetime' in record:
                dt = pd.to_datetime(record['datetime'])
                hour_str = dt.strftime("%Y/%m/%d %H:00")
                date_str = dt.strftime("%Y/%m/%d")
                hourly_records.append({
                    'device': record['device'],
                    'datetime': hour_str,
                    'date': date_str,
                    'PM2.5': record.get('PM2.5'),
                    'PM10': record.get('PM10')
                })

        for record in moenv_records:
            try:
                dt = pd.to_datetime(record['monitordate'])
                hour_str = dt.strftime("%Y/%m/%d %H:00")
                date_str = dt.strftime("%Y/%m/%d")
                itemid = str(record['itemid'])
                station_name = record.get('station_name', '')
                concentration = clean_concentration(record.get('concentration'))
                if concentration is not None:
                    hourly_records.append({
                        'device': station_name,
                        'datetime': hour_str,
                        'date': date_str,
                        'PM2.5': concentration if itemid == '33' else None,
                        'PM10': concentration if itemid == '4' else None
                    })
            except:
                pass

        if hourly_records:
            hourly_df = pd.DataFrame(hourly_records)
            hourly_avg = hourly_df.groupby(['device', 'datetime', 'date']).agg(
                {'PM2.5': 'mean', 'PM10': 'mean'}).reset_index()

            # è½‰æ›ç‚º datetime ç‰©ä»¶å¾Œæ’åº
            hourly_avg['datetime_sort'] = pd.to_datetime(hourly_avg['datetime'])
            hourly_avg = hourly_avg.sort_values('datetime_sort').reset_index(drop=True)

            # å–å¾—æ‰€æœ‰å¯ç”¨çš„æ—¥æœŸ
            available_dates = sorted(hourly_avg['date'].unique())

            # æ—¥æœŸé¸æ“‡ä¸‹æ‹‰é¸å–®
            selected_date = st.selectbox(
                "é¸æ“‡æ—¥æœŸ",
                options=available_dates,
                index=0
            )

            # ç¯©é¸é¸å®šæ—¥æœŸçš„è³‡æ–™ï¼Œä¸¦ç¢ºä¿æ’åºæ­£ç¢º
            filtered_hourly = hourly_avg[hourly_avg['date'] == selected_date].copy()
            filtered_hourly = filtered_hourly.sort_values('datetime_sort').reset_index(drop=True)

            if not filtered_hourly.empty:
                # PM2.5 æ¯å°æ™‚å¹³å‡è¶¨å‹¢
                # PM2.5 æ¯å°æ™‚å¹³å‡è¶¨å‹¢
                fig_pm25_h = go.Figure()
                for station in available_stations:
                    data = filtered_hourly[filtered_hourly['device'] == station].dropna(subset=['PM2.5'])
                    if not data.empty:
                        fig_pm25_h.add_trace(go.Scatter(
                            x=data['datetime_sort'],  # æ”¹ç”¨ datetime_sort
                            y=data['PM2.5'],
                            mode='lines+markers',
                            name=station,
                            line=dict(width=2),
                            marker=dict(size=6)
                        ))
                fig_pm25_h.add_hline(y=30, line_dash="dash", line_color="red", annotation_text="æ³•è¦æ¨™æº– 30")
                fig_pm25_h.update_layout(
                    title="PM2.5 æ¯å°æ™‚å¹³å‡è¶¨å‹¢ - " + selected_date,
                    xaxis_title="æ™‚é–“",
                    yaxis_title="PM2.5 (Î¼g/mÂ³)",
                    height=450,
                    xaxis=dict(
                        tickangle=-45,
                        tickformat='%H:%M'  # åªé¡¯ç¤ºæ™‚é–“
                    )
                )
                st.plotly_chart(fig_pm25_h, use_container_width=True)

                # PM10 æ¯å°æ™‚å¹³å‡è¶¨å‹¢
                fig_pm10_h = go.Figure()
                for station in available_stations:
                    data = filtered_hourly[filtered_hourly['device'] == station].dropna(subset=['PM10'])
                    if not data.empty:
                        fig_pm10_h.add_trace(go.Scatter(
                            x=data['datetime_sort'],  # æ”¹ç”¨ datetime_sort
                            y=data['PM10'],
                            mode='lines+markers',
                            name=station,
                            line=dict(width=2),
                            marker=dict(size=6)
                        ))
                fig_pm10_h.add_hline(y=75, line_dash="dash", line_color="red", annotation_text="æ³•è¦æ¨™æº– 75")
                fig_pm10_h.update_layout(
                    title="PM10 æ¯å°æ™‚å¹³å‡è¶¨å‹¢ - " + selected_date,
                    xaxis_title="æ™‚é–“",
                    yaxis_title="PM10 (Î¼g/mÂ³)",
                    height=450,
                    xaxis=dict(
                        tickangle=-45,
                        tickformat='%H:%M'
                    )
                )
                st.plotly_chart(fig_pm10_h, use_container_width=True)

                st.caption("ğŸ“Š " + selected_date + " å…±é¡¯ç¤º " + str(len(filtered_hourly)) + " å€‹å°æ™‚çš„å¹³å‡è³‡æ–™")
            else:
                st.warning("âš ï¸ " + selected_date + " æ²’æœ‰è³‡æ–™")
        else:
            st.warning("âš ï¸ æ²’æœ‰æ¯å°æ™‚è³‡æ–™")

    st.divider()
    st.subheader("ğŸ“Š çµ±è¨ˆæ‘˜è¦")
    pm25_stats = {'æ¸¬ç«™': [], 'æœ€å°': [], 'æœ€å¤§': []}
    pm10_stats = {'æ¸¬ç«™': [], 'æœ€å°': [], 'æœ€å¤§': []}
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_stats['æ¸¬ç«™'].append(station)
            pm25_stats['æœ€å°'].append(int(station_data['PM2.5'].min()))
            pm25_stats['æœ€å¤§'].append(int(station_data['PM2.5'].max()))
            pm10_stats['æ¸¬ç«™'].append(station)
            pm10_stats['æœ€å°'].append(int(station_data['PM10'].min()))
            pm10_stats['æœ€å¤§'].append(int(station_data['PM10'].max()))

    pm25_df = pd.DataFrame(pm25_stats).set_index('æ¸¬ç«™').T
    pm10_df = pd.DataFrame(pm10_stats).set_index('æ¸¬ç«™').T

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**PM2.5 (æ³•è¦æ¨™æº–: 30Î¼g/mÂ³)**")
        st.dataframe(pm25_df, use_container_width=True, height=100)
    with col2:
        st.markdown("**PM10 (æ³•è¦æ¨™æº–: 75Î¼g/mÂ³)**")
        st.dataframe(pm10_df, use_container_width=True, height=100)

    st.subheader("ğŸ’¾ åŒ¯å‡ºè³‡æ–™")

    # æº–å‚™ CSV å…§å®¹
    csv_lines = []

    # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸå§‹æ¯å°æ™‚è³‡æ–™
    csv_lines.append("========== åŸå§‹æ¯å°æ™‚è³‡æ–™ ==========")
    csv_lines.append("")

    hourly_header = ['æ—¥æœŸæ™‚é–“', 'æ¸¬ç«™', 'PM2.5', 'PM10']
    csv_lines.append(','.join(hourly_header))

    # åˆä½µ AirLink å’Œç’°ä¿ç½²çš„æ¯å°æ™‚è³‡æ–™
    all_hourly = []

    for record in airlink_records:
        if 'datetime' in record:
            all_hourly.append({
                'datetime': record['datetime'],
                'device': record['device'],
                'PM2.5': record.get('PM2.5', ''),
                'PM10': record.get('PM10', '')
            })

    for record in moenv_records:
        try:
            datetime_str = pd.to_datetime(record['monitordate']).strftime("%Y/%m/%d %H:%M")
            itemid = str(record['itemid'])
            station_name = record.get('station_name', '')
            concentration = clean_concentration(record.get('concentration'))

            if concentration is not None:
                existing = next(
                    (r for r in all_hourly if r['datetime'] == datetime_str and r['device'] == station_name), None)
                if existing:
                    if itemid == '33':
                        existing['PM2.5'] = concentration
                    elif itemid == '4':
                        existing['PM10'] = concentration
                else:
                    all_hourly.append({
                        'datetime': datetime_str,
                        'device': station_name,
                        'PM2.5': concentration if itemid == '33' else '',
                        'PM10': concentration if itemid == '4' else ''
                    })
        except:
            pass

    hourly_df_export = pd.DataFrame(all_hourly)
    if not hourly_df_export.empty:
        hourly_df_export['datetime_sort'] = pd.to_datetime(hourly_df_export['datetime'])
        hourly_df_export = hourly_df_export.sort_values(['device', 'datetime_sort'])

        for _, row in hourly_df_export.iterrows():
            pm25_val = str(round(row['PM2.5'], 1)) if pd.notna(row['PM2.5']) and row['PM2.5'] != '' else ''
            pm10_val = str(round(row['PM10'], 1)) if pd.notna(row['PM10']) and row['PM10'] != '' else ''
            csv_lines.append(','.join([row['datetime'], row['device'], pm25_val, pm10_val]))

    csv_lines.append("")
    csv_lines.append("")

    # ç¬¬äºŒéƒ¨åˆ†ï¼šæ¯æ—¥å¹³å‡å½™æ•´è¡¨
    csv_lines.append("========== æ¯æ—¥å¹³å‡å½™æ•´è¡¨ ==========")
    csv_lines.append("")

    header = ['æ—¥æœŸ'] + ['PM2.5', 'PM10'] * len(available_stations)
    csv_lines.append(','.join(header))

    subheader = ['']
    for station in available_stations:
        subheader.extend([station, ''])
    csv_lines.append(','.join(subheader))

    for _, row in result_df.iterrows():
        row_data = [row['æ—¥æœŸ']]
        for station in available_stations:
            pm25_col = station + '_PM2.5'
            pm10_col = station + '_PM10'
            row_data.append(str(int(row[pm25_col])) if pd.notna(row[pm25_col]) else '')
            row_data.append(str(int(row[pm10_col])) if pd.notna(row[pm10_col]) else '')
        csv_lines.append(','.join(row_data))

    csv_lines.append("")
    csv_lines.append("")

    # ç¬¬ä¸‰éƒ¨åˆ†ï¼šçµ±è¨ˆæ‘˜è¦
    csv_lines.append("========== çµ±è¨ˆæ‘˜è¦ ==========")
    csv_lines.append("")
    csv_lines.append("æŸ¥è©¢æ—¥æœŸ: " + start_dt.strftime('%Y/%m/%d') + " ~ " + end_dt.strftime('%Y/%m/%d'))
    csv_lines.append("")

    pm25_header = ['PM2.5'] + available_stations
    csv_lines.append(','.join(pm25_header))

    pm25_min_row = ['æœ€å°å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_min_row.append(str(int(station_data['PM2.5'].min())))
        else:
            pm25_min_row.append('')
    csv_lines.append(','.join(pm25_min_row))

    pm25_max_row = ['æœ€å¤§å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_max_row.append(str(int(station_data['PM2.5'].max())))
        else:
            pm25_max_row.append('')
    csv_lines.append(','.join(pm25_max_row))

    pm25_avg_row = ['å¹³å‡å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_avg_row.append(str(int(station_data['PM2.5'].mean())))
        else:
            pm25_avg_row.append('')
    csv_lines.append(','.join(pm25_avg_row))

    csv_lines.append("")

    pm10_header = ['PM10'] + available_stations
    csv_lines.append(','.join(pm10_header))

    pm10_min_row = ['æœ€å°å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm10_min_row.append(str(int(station_data['PM10'].min())))
        else:
            pm10_min_row.append('')
    csv_lines.append(','.join(pm10_min_row))

    pm10_max_row = ['æœ€å¤§å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm10_max_row.append(str(int(station_data['PM10'].max())))
        else:
            pm10_max_row.append('')
    csv_lines.append(','.join(pm10_max_row))

    pm10_avg_row = ['å¹³å‡å€¼']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm10_avg_row.append(str(int(station_data['PM10'].mean())))
        else:
            pm10_avg_row.append('')
    csv_lines.append(','.join(pm10_avg_row))

    csv_lines.append("")
    csv_lines.append("è¨»ï¼šPM2.5 æ³•è¦æ¨™æº– 30Î¼g/mÂ³ï¼ŒPM10 æ³•è¦æ¨™æº– 75Î¼g/mÂ³")

    csv_content = '\n'.join(csv_lines)
    filename = "ç©ºå“å®Œæ•´è³‡æ–™_" + start_dt.strftime('%Y%m%d') + "_" + end_dt.strftime('%Y%m%d') + ".csv"

    st.download_button(
        "ğŸ“¥ ä¸‹è¼‰å®Œæ•´ CSV æª”æ¡ˆï¼ˆå«åŸå§‹è³‡æ–™ï¼‰",
        data=csv_content.encode('utf-8-sig'),
        file_name=filename,
        mime="text/csv",
        use_container_width=True
    )

    for _, row in result_df.iterrows():
        date_parts = row['æ—¥æœŸ'].split('/')
        year = int(date_parts[0]) - 1911
        month = int(date_parts[1])
        day = int(date_parts[2])
        date_display = str(year) + "/" + str(month) + "/" + str(day)
        row_data = [date_display]
        for station in available_stations:
            pm25_col = station + '_PM2.5'
            pm10_col = station + '_PM10'
            row_data.append(str(int(row[pm25_col])) if pd.notna(row[pm25_col]) else '')
            row_data.append(str(int(row[pm10_col])) if pd.notna(row[pm10_col]) else '')
        csv_lines.append(','.join(row_data))

    csv_lines.append('')
    csv_lines.append(start_dt.strftime('%Y/%m/%d') + "~" + end_dt.strftime('%Y/%m/%d'))

    pm25_header = ['PM2.5'] + available_stations
    csv_lines.append(','.join(pm25_header))
    pm25_min_row = ['æœ€å°']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_min_row.append(str(int(station_data['PM2.5'].min())))
        else:
            pm25_min_row.append('')
    csv_lines.append(','.join(pm25_min_row))

    pm25_max_row = ['æœ€å¤§']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm25_max_row.append(str(int(station_data['PM2.5'].max())))
        else:
            pm25_max_row.append('')
    csv_lines.append(','.join(pm25_max_row))

    pm10_header = ['PM10'] + available_stations
    csv_lines.append(','.join(pm10_header))
    pm10_min_row = ['æœ€å°']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm10_min_row.append(str(int(station_data['PM10'].min())))
        else:
            pm10_min_row.append('')
    csv_lines.append(','.join(pm10_min_row))

    pm10_max_row = ['æœ€å¤§']
    for station in available_stations:
        station_data = all_daily[all_daily['device'] == station]
        if not station_data.empty:
            pm10_max_row.append(str(int(station_data['PM10'].max())))
        else:
            pm10_max_row.append('')
    csv_lines.append(','.join(pm10_max_row))
    csv_lines.append('è¨»ï¼šè¶…éç©ºæ°£å“è³ªæ¨™æº–ä»¥ç²—é«”è¡¨ç¤º')

    csv_content = '\n'.join(csv_lines)
    filename = "ç©ºå“_" + start_dt.strftime('%Y%m%d') + "_" + end_dt.strftime('%Y%m%d') + ".csv"
    st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV æª”æ¡ˆ", data=csv_content.encode('utf-8-sig'), file_name=filename, mime="text/csv",
                       use_container_width=True)

else:
    st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´é¸æ“‡æŸ¥è©¢æ—¥æœŸï¼Œç„¶å¾Œé»æ“Šã€Œé–‹å§‹æŸ¥è©¢ã€æŒ‰éˆ•")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("### ğŸ“‹ åŠŸèƒ½ç‰¹è‰²\n- æ•´åˆ AirLink èˆ‡ç’°ä¿ç½²è³‡æ–™\n- å³æ™‚æŸ¥è©¢èˆ‡è¦–è¦ºåŒ–\n- CSV åŒ¯å‡ºåŠŸèƒ½\n- è¶¨å‹¢åœ–è¡¨åˆ†æ")
    with col2:
        st.markdown("### ğŸ¯ æ¸¬ç«™è³‡è¨Š\n- **AirLink**: å—å€ä¸Šã€å—å€ä¸‹\n- **ç’°ä¿ç½²**: ä»æ­¦ã€æ¥ æ¢“\n- æ”¯æ´è‡ªè¨‚æ—¥æœŸç¯„åœ")
    with col3:
        st.markdown("### ğŸ“Š è³‡æ–™å‘ˆç¾\n- æ¯æ—¥/æ¯å°æ™‚å¹³å‡è¶¨å‹¢åœ–\n- çµ±è¨ˆæ‘˜è¦èˆ‡æ¯”è¼ƒ\n- åŒ¯å‡º CSV å ±è¡¨")